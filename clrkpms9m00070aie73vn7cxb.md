---
title: "성능 향상을 위한 인프라 구조"
datePublished: Fri Jan 19 2024 14:02:26 GMT+0000 (Coordinated Universal Time)
cuid: clrkpms9m00070aie73vn7cxb
slug: 7isx64qlio2wpeydgeydhcdsnittlzwg7j247zse6528ioq1royhsa
tags: infrastructure

---

# OVERVIEW

성능 이슈가 생겼을 때 어디부터 봐야할지 몰라 학습한 부분이다.

응답과 처리량이라는 성능 지표, 병목 현상, 해결을 위한 접근 방법을 알 수 있다.

# 성능 문제의 두 가지 원인

시스템 성능을 가리킬 때 응답(Response)와 처리량(Throughput)이라는 지표가 자주 사용된다.

## 응답

* 처리 하나당 소요 시간을 의미
    
* 검색 엔진에서 키워드를 입력해서 '검색 버튼을 누른 후 검색 결과라 표시되기까지 걸리는 시간
    
* 서비스를 이용하는 한 명의 사용자 관점의 지표
    
* 응답 문제는 로그나 실제 장비 시험을 통해 구체적으로 어떤 계층에서 발생하는지 파악해야 한다.
    
* 응답 시간에 포함되는 시간
    
    * 웹 브라우저로 화면을 클릭한 후 요청이 실행되기까지의 시간
        
    * 클라이언트 PC-웹 서버 간 네트워크 통신 시간
        
    * 웹 서버의 처리 시간
        
    * 웹 서버-AP 서버 간 네트워크 통신 시간
        
    * AP 서버 처리 시간
        
    * AP 서버-DB 서버 간 네트워크 통신 시간
        
    * 웹 브라우저에서 결과를 표시하는 시간
        
* '시스템이 느려', '클릭해도 화면이 표시되지 않아'와 같은 문제는 응답 시간에 문제가 있을 가능성이 높기 때문에 먼저 이 관점으로 조사해야 한다.
    
* 하지만 데이터가 물리적으로 이동하는 이상, 응답 시간에는 반드시 물리적 제약이 존재한다.
    

## 처리량

* 단위 시간당 처리하는 양을 의미
    
* 검색 엔진이 초당 받아들이는 사용자 수
    
* 서비스 제공자 관점의 지표
    
* 대량의 데이터를 교환하고 싶은데 영역이 부족한 경우에 처리량 문제가 발생한다.
    
* 예를 들어 CPU나 메모리 주변 처리량은 높고 CPU에서 먼 디스크나 네트워크 통신 대역에서는 처리량이 낮아 병목 현상이 발생하기 쉽다.
    
* CPU가 처리를 감당하지 못하는 처리가 올 때 '대기 행렬'이 발생해서 처리량 한계를 초과할 수 있다.
    
* 응답과 처리량은 상관 관계
    
    * 응답이 매우 느린 시스템에서는 다수의 사용자 요청이 시스템 내에 누적되므로 전체 처리량이 낮아진다
        
    * 처리량이 포화 상태가 되면 리소스가 부족해져 응답도 느려진다
        

# 병목 현상

![Bottleneck Analysis | Creative Safety Supply](https://cdn11.bigcommerce.com/s-10c6f/template/images/articles/bottleneck.png align="left")

병의 목 부분이 좁기 때문에 아무리 다른 부분이 넓더라도 흐르는 물의 양은 목의 두께에 의해 제한된다.

## 병목 현상은 어떻게 해결하는가?

1. 성능 분석의 시작은 먼저 이 병목 현상이 발생하고 있는 위치를 정확히 파악하는 것이다.
    
    * 책에서는 시작이라고만 표현하지만 여기다 *시작이 반이다.* 라는 말을 덧붙이고 싶다.
        
    * 모니터링 툴을 통해 <mark>서버의 처리량</mark>과 <mark>응답 상황 로그</mark>를 구하여 병목 위치를 찾아야 한다
        
2. 병목 위치를 찾았다면 해결해야 한다. 두 가지 해결 방법이 있다.
    
    * 튜닝
        
        * 병목 위치를 세분화 하여 병목을 집중적으로 파헤친다.
            
    * 시스템 이용자 수 제한
        
        * 대부분의 병목 현상은 당초 예상했던 부하보다 많은 부하가 걸려서 발생하게 된다.
            
        * '해당 사이트는 트래픽 초과로 차단되었습니다'라고 표시되는 것은 웹 서버 계층에서 처리량을 제어하는 것
            
        * 이와 관련해서 직접 써본 기술은 Rate Limit 라이브러리인 bucket4j가 있다
            
        * Rate Limit이란 API 호출 횟수를 제한하는 전략이다.
            
        * 다만 사용자에게 에러를 반환하는 것이 전부라서 근본적인 해결책은 아니므로 시스템 전체 허용량을 늘리는 접근법을 같이 사용할 필요가 있다.
            

## CPU 병목

* CPU 사용률이 높다고 해서 나쁜 것도 아니고, 반대로 사용률이 낮다고 해서 좋은 것도 아니다.
    
* 햄버거 가게의 점원이 바쁘게 움직이고 있다고 해서 가게가 붐빈다고 볼 수 있을까?  
    손님은 햄버거만 빨리 받는다면 아무 불만이 없다.
    
* 프로세스가 효율적으로 처리를 진행하다 보면 CPU 사용률이 100%가 될 수 있다.
    
* 다른 계층의 처리량이 매우 좋기 때문에 최종적으로는 CPU에서 병목 현상이 발생한다는 것을 의미하기 때문이다.
    
* <mark>CPU 사용률 급증이 문제인 건지 파악하려면 사용자 관점의 응답 속도나 시스템 전체 처리량을 확인해야 한다.</mark>
    
* 사용자가 만족하지 못한다면 CPU 사용률이 높은 상태 자체를 문제로 생각하지 말고 근본적인 원인을 조사하도록 하자.
    
* CPU가 문제가 되는 경우는 크게 두 가지로 나뉜다
    
    * CPU를 이용하는 처리가 많아서 대기 행렬 발생
        
    * CPU 응답이 느림
        

### 대기 행렬 병목 현상

햄버거 비유

* 햄버거 가게 점원이 100%로 일하고 있어도 손님 줄이 줄어들지 않는다면 점원이 병목 지점이 된다.
    
* CPU 사용률이 높고 OS상에서 가동하고 있는 프로세스 수가 많으면 대기 행렬에서 병목 현상이 발생한다.
    
* 커널 영역에는 OS에 CPU 대기 프로세스를 관리하는 큐가 있다.
    
* 점원이 아무리 열심히 일하고 있어도 손님 줄이 계속 길어지다 보면 사장이 나와서 사과를 해야할 수도 있다.
    
* 햄버거 가게에서는 계산대와 점원을 늘리면 처리량이 높아진다.
    
* 또는 주문 시스템 자체를 개선해서 고객 한 명당 처리 시간을 단축하는 것도 방법이다.
    
* <mark>대기 행렬의 병목 현상은 처리량 측면의 문제다.</mark>
    

해결 방법

* CPU를 코어 수가 많은 것으로 변경
    
* CPU 추가 탑재
    
* 개별 처리 튜닝
    

### 응답 병목 현상

햄버거 비유

* 처리량 문제를 해결해도 응답 문제가 반드시 해결되는 것은 아니다.
    
* 햄버거 가게 점원의 계산 속도가 느리거나, 햄버거 만드는 속도가 느리면 점원이 아무리 늘어난다 해도 <mark>한 명의 고객이 기다리는 응답 시간에는 큰 차이가 없다.</mark>
    

해결 방법

* 처리 능력 향상
    
    * 스케일 업(처리 능력 두 배인 점원 고용)
        
    * 처리 능력이 두 배인 점원이 일을 하면 처리 시간이 반으로 줄어들고 응답 시간도 줄어드는 것을 기대할 수 있다.
        
    * CPU로 따지면 클럭 수가 두 배가 되면 응답 시간이 반으로 줄어든다.
        
    * 하지만 요새 CPU는 클럭 수 차이가 크지 않아서 극적인 개선 효과는 기대하기 어렵다.
        
* 병렬 처리
    
    * 처리를 분할해서 다수의 CPU 코어에게 동시 처리를 시키는 것이다.
        
    * 점원 한 명이 햄버거 준비, 음료 준비, 계산 등을 전부 하지 않고 각각 작업의 담당 점원을 고용하는 것이다.
        
    * 처리를 병렬화 할 수 있는가가 중요 사항이 된다.
        
    * 처리에 따라서는 병렬화를 하기 어려울 수 있고 병렬화가 안 되는 경우는 CPU 코어 수를 늘리거나 서버를 늘려 스케일 아웃을 해도 큰 개선 효과를 보기는 어렵다.
        
    * 병렬화 검토는 인프라만으로 한계가 있어 애플리케이션 개발자의 협조가 필요하다.
        

### CPU 사용률이 오르지 않는다

![](https://cdn.hashnode.com/res/hashnode/image/upload/v1705665339617/7fcbec1a-9557-40f5-a898-b1131fe49332.png align="center")

* 대부분의 애플리케이션에서는 CPU 사용률이 100%에 도달하는 경우가 거의 없다.  
    그 전에 디스크 I/O나 네트워크 I/O에서 막히는 경우가 많기 때문이다.
    
* 동기 I/O는 시스템 콜로 커널에 명령이 가지만, 이것이 완료되지 않으면 프로세스가 다음 처리를 진행하지 않는다.
    
* 이 상태의 프로세스는 대기 상태가 되며 CPU를 이용할 수 없기 때문에 CPU 사용률은 올라가지 않는다.
    
* CPU 사용률은 낮아도 I/O 대기 큐에서 대기하는 프로세스 수가 증가한다.
    
* 이 상태를 개선할 수 있는 방법이 몇 가지가 있다
    
    * 처리 다중화
        
        * 스레드를 여러 개 가동해서 동기 I/O 명령을 스레드 단위로 병행해서 실행하면 CPU 사용률도, I/O 부하도 증가한다.
            
        * 서버 전체의 리소스 사용을 개선할 수 있다.
            
    * I/O 비동기화
        
        * 비동기 I/O를 이용하면 프로세스는 I/O 처리 완료를 기다리지 않고 다음으로 넘어갈 수 있다.
            
        * CPU 처리와 I/O 처리를 동시에 할 수 있어 리소스 사용이 개선된다.
            
    * 하드 디스크와 같이 물리적으로 동작하는 구조나 전기 신호로 실행되는 구조기 때문에 성능은 물리 법칙과의 싸움이라고 할 수 있다.
        
    * 즉 메모리 액세스, 디스크 I/O, CPU 명령 등이 얼마나 하드웨어 성능을 최대한 끌어낼 수 있는가가 성능에 직결된다.
        
    * 그러므로 프로그램이 실행될 때 하드웨어 동작을 이해하는 것이 중요하다고 본다.
        

## 메모리 병목 현상

### 영역 부족

* 프로세스가 가동해서 어떤 처리를 하려면 반드시 전용 메모리 영역이 필요하다.
    
* 하지만 서버상의 메모리 영역은 유한하다.
    
    * 64비트 장비에서는 2의 64승 비트 영역까지 이용할 수 있다
        
    * 이는 172억 GB에 해당한다. 매우 큰 영역이지만 유한하다.
        
* <mark>이 유한성을 해결하기 위해 OS 커널 측에서 페이징 또는 스와핑이라는 처리를 한다.</mark>
    
* 이 처리를 하면 빈 메모리가 확보된다.
    
* 부족한 메모리 영역은 디스크 영역을 보완하여 가상적인 큰 메모리가 있다는 것을 보여주는 기술이다.
    
* 이를 가상 메모리 Virtual Memory라고 한다.
    
    * 자신이 가진 영역이 큰 것처럼 허세를 부린다.
        
    * 허세기 때문에 당연히 실제로는 제한이 있다.
        
    * 메모리가 가득 차게 되면 넘친 데이터는 디스크에 저장되며 해당 프로세스가 다시 이 영역을 이용할 때 메모리로 되돌리는 형태다.
        

## 디스크 I/O 병목

* 디스크는 메모리와 비교해서 매우 느리다. SSD 같은 고속 디스크가 있어도 말이다.
    
* 외부 저장소, 순차 I/O와 랜덤 I/O가 있는데 이 부분은 이해가 가지 않아 건너 뛰었다.
    

## 네트워크 I/O 병목

* <mark>네트워크를 경유한 I/O는 CPU 버스나 메모리 간 I/O보다도 응답 시간 오버헤드가 크다.</mark>
    
* 네트워크 I/O가 적게 발생할수록 성능이 개선된다.
    
* 병렬화를 하여 네트워크 대역을 최대로 사용한다.
    
* 압축을 통해 '전송량'을 줄이는 것도 한 가지 접근 방법이 된다.
    
    * 다만 압축 및 압축 해제 시 CPU 오버헤드 발생 가능
        

## 애플리케이션 병목

인프라는 스케일업과 스케일아웃 등의 개념으로 개선이 가능하다.

알고리즘의 문제라면 인프라 개선을 아무리 해봐도 응답과 처리량을 개선할 수 없다.

### 데이터 갱신의 병목 현상

* 데이터베이스를 이용한 애플리케이션에서 자주 발생하는 것이 특정 데이터에 의존하는 처리가 병목 지점이 되는 것이다.
    
* 예를 들어 판매 개수를 기록해야 하는데 '반드시 재고 개수에서 1을 뺀다'라는 처리가 있다면 일반적으로는 테이블의 특정 레코드 값을 변경하도록 구현된다.
    
    * 스레드가 두 개 있어도 서로 같은 데이터를 갱신하기 전까지는 다음 처리를 하지 않는다.
        
    * 한 스레드가 값을 갱신 중일 경우 (락 상태) 나머지 하나는 대기한다.
        
    * 여기서 병목이 발생할 수 있다.
        
    * 재고 확인을 실시간으로 해야 하고 엄격하게 해야 하는 경우에는 이 형태가 필수지만 개선할 수 있는 방법도 있다.
        
* 값의 캐시화
    
    * DB에 쿼리를 던지는 것이 병목 지점이 된다면 더 가까운 장소에 캐시화한다.
        
    * 스레드가 두 개 있어도 서로 같은 데이터를 갱신하기 전까지는 다음 처리를 하지 않는다.
        
    * 한 스레드가 값을 갱신 중일 경우 (락 상태) 나머지 하나는 대기를 해야 하지만 캐시화 덕분에 대기 시간이 짧아진다.
        
    * 동기화에 주의해야 한다.
        
* 병목 지점의 분할
    
    * 재고 확인을 엄밀하게 처리하지 않고 레코드를 두 개로 나누는 형태다.
        
    * 예를 들어 재고가 200개라면 레코드를 100개씩 나눈다.
        
    * 이 경우 한 번에 두 개를 처리할 수 있어 다중화가 가능해진다.
        
    * 스레드가 두 개 있어도 서로 같은 데이터를 갱신하기 전까지는 다음 처리를 하지 않는다.
        
    * 같은 데이터를 두 개의 레코드로 분할하면 쿼리는 병렬화하여 실행한다.
        
    * 레코드 간 데이터 일치성 문제와 한쪽이 먼저 고갈될 경우의 문제가 발생할 수 있다.
        

### 외부 질의의 병목 현상

* 서비스는 외부 서비스를 호출하기도 한다. 이 부분이 병목 현상이 되기도 한다.
    
* 예를 들어 인증 처리를 전담하는 서버에 호출을 해야하는 경우,  
    한 번 사용자 정보를 취득하고 애플리케이션에서 일차 파일을 캐싱하여 차이만 확인하도록 하였더니 병목 현상이 사라지기도 한다.